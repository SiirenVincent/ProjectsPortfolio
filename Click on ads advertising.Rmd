---
output:
  word_document: default
  html_document: default
---
# Week 12 Independent Project

## Defining The Question

### a) Specifying the Question.

 Identify which individuals are most likely to click on her ads in Cryptography course website.

### b) Defining the Metrics for Success.

For this study, we will perform conclusive Exploratory Data Analysis to enable us identify individuals who are most likely to click on ads.

### c) Understanding the context.

A Kenyan entrepreneur has created an online cryptography course and would want to advertise it on her blog. She currently targets audiences originating from various countries. In the past, she ran ads to advertise a related course on the same blog and collected data in the process. Using the data previously collected, she is looking to do a study to identify which individuals are most likely to click on her ads.

### d) Experimental Design.

The project was undertaken using the following design Datasets(http://bit.ly/IPAdvertisingData)

- Load dataset

- Data Cleaning

- Performing Exploratory Analysis

- Conclusion

### e) Data Relevance


Data is provided was collected in the past but from the same blog hence it is very suitable for this study.

Definition of Variables Daily Time Spent on Site

Age

Area

Income

Daily Internet Usage

Ad Topic Line

City

Male

Country

Timestamp

Clicked on Ad

## Data Preparation

### Importing the Libraries
```{r}
# load libraries
library(tidyverse)
library(data.table)
options(warn = -1)
```


### Loading the data
```{r}
#load data
df <- fread('http://bit.ly/IPAdvertisingData')
```
```{r}
#priview the first 6 rows
head(df)
```
```{r}
# Checking the class of our dataset
class(df)
```
```{r}
# Find the number of column and rows
class(df); ncol(df); nrow(df)
```
We have 10 columns and 1000 rows
```{r}
#checking the first 10 rows in our dataset
(print(head(df, n=10)))
```
```{r}
#checking the last 10 rows in our dataset
(print(tail(df, n=10)))
```
```{r}
# Check the structure of the data 
print(str(df))
```
The advertising data is a dataframe/datatable containing 1000 observations and 10 variables. The variables has discrete and countinous values and also it has character values.

```{r}
#distribution of dataset on gender
table(df$gender)
```

There are more female that male who use the site

```{r}
#distribution of dataset  on click on ad
table(df$clicked_on_ad)
```
The dataset is well balanced with a ratio of 1:1 of those who click ad and those who did not 

## Data Cleaning

### Renaming of columns

```{r}
# Changing column names to lower and replacing spaces with an underscore for readability
colnames(df) = tolower(str_replace_all(colnames(df), c(' ' = '_')))

# Checking whether the column names have been renames appriopriately
print(colnames(df))
```
```{r}
# The male column should be renamed to gender
colnames(df)[colnames(df) == 'male'] = 'gender'
head(df)
```


### Finding missing values
```{r}
# 
#check missing values in each column
colSums(is.na(df))

```
### Finding Duplicates values
```{r}
# find the duplicated rows 
# 
anyDuplicated(df)
```

### Finding Outliers
```{r}
# get numerical columnns
num <- df %>% select_if(is.numeric)
num
```



```{r}
#check for outliers in the numerical columns
boxplot(num)
```
From the results we can conclude that there are outliers in Area Income columns we will not delete them because we will get insights from them

```{r}
non_outliers <- 47032 - 1.5 * IQR(df$area_income) 
df$area_income[df$area_income < non_outliers]<- non_outliers

boxplot(df$area_income)
```



# Exploratory Data Analysis

## Univariate Analysis
```{r}
# checking for the dataset statistical summary
(summary(num))

```


### Mean
```{r}

print("Age")
mean(replace(df$age, df$clicked_on_ad==0, NA), na.rm = TRUE)

print("Area Income")
mean(replace(df$area_income, df$clicked_on_ad==0, NA), na.rm = TRUE)

print("Daily internet usage")
mean(replace(df$daily_internet_usage, df$clicked_on_ad==0, NA), na.rm = TRUE)

print("Daily time spent on site")
mean(replace(df$daily_time_spent_on_site, df$clicked_on_ad==0, NA), na.rm = TRUE)
```


### range

```{r}
print("Age")
range(replace(df$age, df$clicked_on_ad==0, NA), na.rm = TRUE)

print("Area Income")
range(replace(df$area_income, df$clicked_on_ad==0, NA), na.rm = TRUE)

print("Daily internet usage")
range(replace(df$daily_internet_usage, df$clicked_on_ad==0, NA), na.rm = TRUE)

print("Daily time spent on site")
range(replace(df$daily_time_spent_on_site, df$clicked_on_ad==0, NA), na.rm = TRUE)
```

### Interquartile range

```{r}
# Finding the Quantiles for numerical columns
# Quantiles of daily time on site
print("Quantiles of daily time on site")
daily_time_quantiles <-quantile(df$daily_time_on_site)
daily_time_quantiles

# Quantiles of age
print("Quantiles of age")
age_quantiles <-quantile(df$age)
age_quantiles

# Quantiles of area income
print("Quantiles of area income")
area_income_quantiles <-quantile(df$area_income)
area_income_quantiles

# Quantiles of daily internet usage
print("Quantiles of daily internet usage")
daily_internet_usage_quantiles <-quantile(df$daily_internet_usage)
daily_internet_usage_quantiles
```


### Standard deviation
```{r}
print("Age")
sd(replace(df$age, df$clicked_on_ad==0, NA), na.rm = TRUE)

print("Area Income")
sd(replace(df$area_income, df$clicked_on_ad==0, NA), na.rm = TRUE)

print("Daily internet usage")
sd(replace(df$daily_internet_usage, df$clicked_on_ad==0, NA), na.rm = TRUE)

print("Daily time spent on site")
sd(replace(df$daily_time_spent_on_site, df$clicked_on_ad==0, NA), na.rm = TRUE)
```

### Variance

```{r}
print("Age")
var(replace(df$age, df$clicked_on_ad==0, NA), na.rm = TRUE)

print("Area Income")
var(replace(df$area_income, df$clicked_on_ad==0, NA), na.rm = TRUE)

print("Daily internet usage")
var(replace(df$daily_internet_usage, df$clicked_on_ad==0, NA), na.rm = TRUE)

print("Daily time spent on site")
var(replace(df$daily_time_spent_on_site, df$clicked_on_ad==0, NA), na.rm = TRUE)
```


### Skewness

```{r}
#skewness of Area Income for those who click ad
library(moments)
print("Age")
skewness(replace(df$age, df$clicked_on_ad==0, NA), na.rm = TRUE)

print("Area Income")
skewness(replace(df$area_income, df$clicked_on_ad==0, NA), na.rm = TRUE)

print("Daily internet usage")
skewness(replace(df$daily_internet_usage, df$clicked_on_ad==0, NA), na.rm = TRUE)

print("Daily time spent on site")
skewness(replace(df$daily_time_spent_on_site, df$clicked_on_ad==0, NA), na.rm = TRUE)

```

All the variables has positive value this implies that the distribution of the data is slightly skewed to the right or positive skewed. accept for area income which negative which means it is skewed to left

### Kurtosis

```{r}
print("Age")
kurtosis(replace(df$age, df$clicked_on_ad==0, NA), na.rm = TRUE)

print("Area Income")
kurtosis(replace(df$area_income, df$clicked_on_ad==0, NA), na.rm = TRUE)

print("Daily internet usage")
kurtosis(replace(df$daily_internet_usage, df$clicked_on_ad==0, NA), na.rm = TRUE)

print("Daily time spent on site")
kurtosis(replace(df$daily_time_spent_on_site, df$clicked_on_ad==0, NA), na.rm = TRUE)
```

The distribution of the data is platykurtic, since the computed values for all the varibles are less than 3 accept variable daily internet usage.

### Histogram
```{r}
# Histogram of Age
ggplot(data = df, mapping = aes(x = age)) +
  geom_histogram(bins = 20, fill = "green") +
  labs(x = "Age") +
  ggtitle("Histogram of Age") +
  theme(plot.title = element_text(hjust = 0.5))
```
It is skewed to left. Age between 25 and 45 visit the site mostly

```{r}
# Histogram of Income
ggplot(data = df, mapping = aes(x = area_income)) +
  geom_histogram(bins = 20, fill = "blue") +
  labs(x = "Area Income") +
  ggtitle("Histogram of Income") +
  theme(plot.title = element_text(hjust = 0.5))
```
It is skewed to right, people whose income ranges between 45000 and 75000 mostly visit the site. 

```{r}
# Histogram of Daily Internet usage
ggplot(data = df, mapping = aes(x = daily_internet_usage)) +
  geom_histogram(bins = 20,fill="purple") +
  labs(x = "Daily Internet usage") +
  ggtitle("Histogram of Daily Internet usage") +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
# Histogram of Daily time spent on internet
ggplot(data = df, mapping = aes(x = daily_time_spent_on_site)) +
  geom_histogram(bins = 30) +
  labs(x = "Daily time spent on interne") +
  ggtitle("Histogram of Daily time spent on internet") +
  theme(plot.title = element_text(hjust = 0.5))

```
Most of the people who are above 60 visits the site mostly

```{r}

#Which gender is mainly active on the blog?
ggplot(data = df) +
  geom_bar(mapping = aes(x = gender))

#Assuming that if male = 1 then we can conclude that more females
# frequennt the blog more as compared to males
```

Female visit the site mostly than male

## Bivariate and Multivariate Analysis.
### Correlation

```{r}
library(corrplot)
#Get the correlation matrix
res = cor(num)
#Plotting a correlation plot

corrplot(res, method="color",addCoef.col = "black", 
         tl.col="black", tl.srt=45)
```
There are a bit of correlation between Daily time spent on site and Daily internet usage

```{r}
x <- df$daily_internet_usage
y <-  df$daily_time_spent_on_site
# Plot with main and axis titles
# Change point shape (pch = 19) and remove frame.
plot(x, y, main = "Time spent on site vs Daily Internet Usage",
     xlab = "Daily Internet Usage", ylab = "Time spent on site",
     pch = 20)
```

The plot shows that there is no correlation between the two columns. But we can see that people who spend less time on site use less internet. Also, most of the people who use alot of internet per day seem to spend most of there time on the site.


```{r}
#Income class and it's relationship to clicking an ad
ggplot(df, 
       aes(x = area_income, 
           fill = clicked_on_ad==1)) +
  geom_density(alpha = 0.4) +
  labs(title = "Income vs chances of clicking on an ad")

```
People from all range of income click on ads as compared to those who do not click ad. should focus on people whose income range on 20000 to 50000 are the ones are likely click ad

```{r}
#Who is likely to click on an ad, female or male?
# stacked bar chart
library(ggplot2)
ggplot(df, 
       aes(x = gender, 
           fill = clicked_on_ad==1)) + 
  geom_bar(position = "stack")
```
There are more female who click on ad than male

```{r}
#Age and it's relationship to clicking an ad
ggplot(df, 
       aes(x = age, 
           fill = clicked_on_ad==1)) +
  geom_density(alpha = 0.4) +
  labs(title = "Age vs chances of clicking on an ad")
```

People who click on ad are disriputed across the age. Those who are in the bracket of 30 to 50 are the ones who click on add mostly

```{r}
#Time on  and it's relationship to clicking an ad
ggplot(df, 
       aes(x = daily_time_spent_on_site, 
           fill = clicked_on_ad==1)) +
  geom_density(alpha = 0.4) +
  labs(title = "daily time spent vs chances of clicking on an ad")
```

People who spend less time on site click on ad unlike those who spend longer time on site


# EDA Conclusion

1. Most of the people who use alot of internet per day seem to spend most of there time on the site.She should target those who spend alot of internet.
2. Those who are in the age bracket of 30 to 50 are the ones who click on ad mostly so she should focus on people who are in age bracket named.
3. Famele who click on ad are more than male so she should forcus on them, without neglecting male because no big difference between them interms of clicking on ad
4. Those who click on ad is distributed across income but those who are in the range of 20000 to 50000 click on ad mostly, so she should consider them.
5.  Those who spend less than 70mins on site mostly click on ad

# Implement the Solution

## Modelling

`
### KNN
```{r}
set.seed(100)

# Randomizing the rows, creates a uniform distribution of 150
random <- runif(150)
df_random <- num[order(random),]

# Selecting the first 6 rows from iris_random
head(df_random)
```



```{r}
dfnum <- as.data.frame(scale(num))
head(dfnum)
```

```{r}
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
df_n <- as.data.frame(lapply(dfnum, normalize))
```

```{r}
Train <- df_n[1:200, ]
Test <- df_n[201:393, ]
Train_labels <- Train[1:200, 6]
Test_labels <- Test[201:393, 5]

```

```{r}
Test
test_target <- as.factor(Test[,6])
test_target
```


```{r}
library(class)    
require(class)
Test_pred <- knn(train = Train, test = Test,
                      cl = Train_labels, k = 21)
Test_pred
```

```{r}
#Model Evaluation
t<-table(factor(Test_pred))
t
t1<-table(test_target,Test_pred)
t1
# Checking the accuracy
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(t1)
```


# Challenge the Solution

I didnt find any need to challenge to question because the accuracy of the model is 100%.




